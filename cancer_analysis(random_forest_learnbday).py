# -*- coding: utf-8 -*-
"""Cancer Analysis(Random Forest Learnbday).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nXcmxtlODk-LgTQbklY6jEgkYkeQW2Gi
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import KFold, cross_val_score
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from urllib.request import urlopen
from sklearn import metrics

data=pd.read_csv('data.csv')

data

data.isna().sum()

data.head()

data.info()

#data.duplicate_values().sum()

data.columns

data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})

data.head()

data.set_index('id', inplace=True)

data.head()

data.shape

data.dtypes

data.describe()

data.drop('Unnamed: 32',axis=1,inplace=True)

data

#spliting data into train and test
X=data.iloc[:,data.columns != 'diagnosis']
Y=data.iloc[:,data.columns == 'diagnosis']

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=20)

Y_train = Y_train.values.reshape(-1)
Y_test = Y_test.values.reshape(-1)

print(Y_train)

Y_train.shape

X_train.shape

'''
from sklearn.preprocessing import StandardScaler
standard_Scaler=StandardScaler()
X_train = standard_Scaler.fit_transform(X_train)
X_test = standard_Scaler.transform(X_test)
'''

from sklearn.linear_model import LogisticRegression
reg=LogisticRegression(random_state=12)
reg.fit(X_train,Y_train)
y_pred=reg.predict(X_test)

from sklearn.metrics import confusion_matrix
conf_matrix=confusion_matrix(Y_test,y_pred)
conf_matrix

'''
param_dist = {'max_depth':[2,3,4,5],
             'bootstrap':[True,False],
             'max_features':['auto','sqrt','log2',None],
             'criterion':['gini','entropy']}

cv_rf = GridSearchCV(rf,cv=10,param_grid=param_dist,n_jobs=3)

cv_rf.fit(X_train,Y_train)
print('Best Parameters using Grid search: \n',cv_rf.best_params_)
''''

#random forest classifier
rf=RandomForestClassifier(criterion='entropy', max_depth=5, max_features='sqrt')

rf.fit(X_train,Y_train)
y_pred=rf.predict(X_test)

rf.score(X_train,Y_train)

rf.score(X_test,Y_test)

conf_matrix1=confusion_matrix(Y_test,y_pred)
conf_matrix1

y_pred.shape

y_pred

conf_matrix1.ravel() #66-TN,0-FP, 4-FN, 44-TP

accuracy = (44+66)/(66+4+44)
accuracy

precision=66/66+4 #for false negetive
precision

Recall=66/66

accuracy=metrics.accuracy_score(Y_test,y_pred)
print('Accuracy:',accuracy)
precision_positive=metrics.precision_score(Y_test, y_pred, pos_label=1)
precision_negative = metrics.precision_score(Y_test, y_pred, pos_label=1)
print('Precision:', precision_positive, precision_negative)
recall_sensitivity = metrics.recall_score(Y_test, y_pred, pos_label=1)
recall_specificity = metrics.recall_score(Y_test, y_pred, pos_label=0)
print('Recall:',recall_sensitivity, recall_specificity)

print(metrics.classification_report(Y_test, y_pred))

